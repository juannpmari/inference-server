# Inference service with sidecar using just kubernetes, suitable for single-node inference.
# for multi-node inference, use RayClusterFleet.
apiVersion: v1
kind: Pod
metadata:
  name: inference-with-sidecar
spec:
  containers:
  - name: inference
    image: inference-image
    command: # pass model name and lora adapter as args

  - name: sidecar
    image: sidecar-image
    command: 
